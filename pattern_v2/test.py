import torch
import torchvision
import torchvision.transforms as T
import cv2
import os
import json
import numpy as np
from PIL import Image

# ì €ìž¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
MODEL_PATH = "ssd_model_optimized.pth"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# SSD ëª¨ë¸ ë¡œë“œ
model = torchvision.models.detection.ssdlite320_mobilenet_v3_large(pretrained=True)
num_classes = 3  # ë°°ê²½(0) + ì²´í¬ë¬´ëŠ¬(1) + ë‹¨ìƒ‰(2)
model.head.classification_head.num_classes = num_classes
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model.to(DEVICE)
model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •

# ë°ì´í„° ë³€í™˜ ì •ì˜
transform = T.Compose([
    T.Resize((300, 300)),  # ðŸ”¥ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ëª¨ë¸ ìž…ë ¥ í¬ê¸°(300x300)ë¡œ ë³€í™˜
    T.ToTensor(),
])

# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë” ë° ê²°ê³¼ ì €ìž¥ í´ë”
TEST_FOLDER = "test"
RESULT_FOLDER = "results"
os.makedirs(RESULT_FOLDER, exist_ok=True)

# í•˜ë‚˜ì˜ ê²°ê³¼ íŒŒì¼ ìƒì„±
RESULT_TXT_PATH = os.path.join(RESULT_FOLDER, "predictions.txt")

# ëˆ„ì  í†µê³„
total_files = 0
files_with_detections = 0
files_without_detections = 0
all_above_scores = []
all_below_scores = []

# annotations ë¶ˆëŸ¬ì˜¤ê¸°
with open("annotation.json", "r") as f:
    annotations_data = json.load(f)

# íŒŒì¼ëª… -> ì‹¤ì œ annotation ë§¤í•‘ìš© dict ìƒì„±
gt_annotations = {}
category_id_to_name = {cat["id"]: cat["name"].capitalize() for cat in annotations_data["categories"]}

for ann in annotations_data["annotations"]:
    image_id = ann["image_id"]
    label_name = category_id_to_name[ann["category_id"]]
    if image_id not in gt_annotations:
        gt_annotations[image_id] = []
    gt_annotations[image_id].append(label_name)

# ðŸ”¥ ì „ì²´ ê²°ê³¼ íŒŒì¼ì„ ìƒì„± ë° ë®ì–´ì“°ê¸° ëª¨ë“œë¡œ ì—´ê¸°
with open(RESULT_TXT_PATH, "w") as result_file:
    result_file.write("== SSD Detection Results ==\n\n")
    
    #COCO format predictions ì €ìž¥ìš© ë¦¬ìŠ¤íŠ¸
    coco_predictions = []

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ ë° ì˜ˆì¸¡
    for filename in os.listdir(TEST_FOLDER):
        if filename.lower().endswith(".jpg") or filename.lower().endswith(".png"):
            total_files += 1

            image_path = os.path.join(TEST_FOLDER, filename)

            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ & í¬ê¸° ë³€í™˜
            image = Image.open(image_path).convert("RGB")
            image_resized = image.resize((300, 300))  # ðŸ”¥ OpenCVì—ì„œ ì¢Œí‘œ ë§¤ì¹­ì„ ìœ„í•´ 300x300ìœ¼ë¡œ ë³€í™˜
            image_tensor = transform(image).unsqueeze(0).to(DEVICE)

            # ì˜ˆì¸¡ ì‹¤í–‰
            with torch.no_grad():
                predictions = model(image_tensor)

            # ðŸ” ì˜ˆì¸¡ëœ ì •ë³´ ë””ë²„ê¹… ì¶œë ¥
            print(f"ðŸ”¹ Processing {filename}")

            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ (OpenCV) ë° í¬ê¸° ë³€í™˜
            image_cv2 = cv2.imread(image_path)
            image_cv2 = cv2.resize(image_cv2, (300, 300))  # ðŸ”¥ í¬ê¸° 300x300ìœ¼ë¡œ ë³€í™˜

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° ë° ê²°ê³¼ ì €ìž¥
            detected = False  # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì¡ŒëŠ”ì§€ ì²´í¬
            result_file.write(f"Filename: {filename}\n")
            result_file.write("Bounding Boxes (x_min, y_min, x_max, y_max), Score, Label\n")

            # ì˜ˆì¸¡ëœ ë°•ìŠ¤ ì •ë³´ ì €ìž¥ìš©
            above_scores = []
            below_scores = []

            for box, score, label in zip(predictions[0]['boxes'].cpu().numpy(),
                                         predictions[0]['scores'].cpu().numpy(),
                                         predictions[0]['labels'].cpu().numpy()):

                # ðŸ”¥ ì²´í¬ë¬´ëŠ¬ì™€ ë‹¨ìƒ‰ì„ êµ¬ë¶„í•˜ì—¬ ìƒ‰ìƒ ë‹¤ë¥´ê²Œ ì ìš©
                if label == 1:  # Checked
                   color = (0, 0, 255)       # ë¹¨ê°„ìƒ‰
                   label_text = "Checked"
                elif label == 2:  # Solid
                   color = (0, 255, 127)       # ì´ˆë¡ìƒ‰
                   label_text = "Solid"
                elif label == 3:  # Stripe
                    color = (255, 0, 0)       # íŒŒëž€ìƒ‰
                    label_text = "Stripe"
                elif label == 4:  # Dotted
                    color = (0, 255, 255)     # ë…¸ëž€ìƒ‰ (ì²­ë¡)
                    label_text = "Dotted"
                elif label == 5:  # Floral
                    color = (255, 105, 180)     # í•‘í¬ìƒ‰
                    label_text = "Floral"
                elif label == 6:  # Animal
                    color = (173, 216, 230)   # ë°ì€ í•˜ëŠ˜ìƒ‰
                    label_text = "Animal"
                elif label == 7:  # Paisley
                   color = (186, 85, 211)    # ì—°ë³´ë¼
                   label_text = "Paisley"
                elif label == 8:  # Printed
                    color = (255, 165, 0)     # ì˜¤ë Œì§€
                    label_text = "Printed"
                elif label == 9:  # Camouflage
                    color = (60, 179, 113)    # ì—°ë…¹ìƒ‰
                    label_text = "Camouflage"
                elif label == 10:  # Text
                    color = (255, 255, 0)     # ë°ì€ ë…¸ëž‘
                    label_text = "Text"
                elif label == 11:  # Logo
                    color = (0, 0, 128)       # ì§„í•œ ë‚¨ìƒ‰
                    label_text = "Logo"
                elif label == 12:  # Pocket
                    color = (192, 192, 192)   # ë°ì€ íšŒìƒ‰
                    label_text = "Pocket"
                else:
                    continue  # ë°°ê²½(0) ë¬´ì‹œ
                
                if score > 0.7:  # ì‹ ë¢°ë„
                    detected = True
                    above_scores.append(score)
                    x_min, y_min, x_max, y_max = map(int, box)
                    cv2.rectangle(image_cv2, (x_min, y_min), (x_max, y_max), color, 1)
                    #cv2.putText(image_cv2, f"{label_text}: {score:.2f}", (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                    text = f"{label_text}: {score:.2f}"
                    (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
                    # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ (ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ìª½)
                    cv2.rectangle(image_cv2, (x_min, y_min - text_height - 8), (x_min + text_width, y_min), color, -1)
                    # í°ìƒ‰ ê¸€ìž ì¶œë ¥
                    cv2.putText(image_cv2, text, (x_min, y_min - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    # ðŸ”¥ TXT íŒŒì¼ì— ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì €ìž¥
                    result_file.write(f"{x_min}, {y_min}, {x_max}, {y_max}, {score:.2f}, {label_text}\n")

                    # COCO formatìš© box ì¶”ê°€
                    coco_predictions.append({
                        "image_id": filename,  # ë˜ëŠ” ì‹¤ì œ image_id ê°’
                        "category_id": int(label),
                        "bbox": [float(x_min), float(y_min), float(x_max - x_min), float(y_max - y_min)],
                        "score": float(score)
                    })

                else: 
                    below_scores.append(score)

            all_above_scores.extend(above_scores)
            all_below_scores.extend(below_scores)

            # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì—†ì„ ê²½ìš° ê²½ê³  ì¶œë ¥
            if not detected:
                print(f"âš ï¸ No valid detections for {filename}")
                result_file.write("No valid detections\n")

            # ðŸ”¹ ì‹¤ì œ ë¼ë²¨ ì •ë³´ ì¶œë ¥ (Ground Truth)
            image_ground_truths = gt_annotations.get(filename, [])
            result_file.write("Bounding box info:\n")
            if image_ground_truths:
                for idx, label_name in enumerate(image_ground_truths, start=1):
                    result_file.write(f" - GT Box {idx}: {label_name}\n")
            else:
                result_file.write(" - No ground truth annotations found\n")


            # í†µê³„ ì •ë³´ ì¶œë ¥
            result_file.write("\nDetection Summary:\n")
            result_file.write(f" - Score >= 0.7: {len(above_scores)} boxes\n")
            result_file.write(f" - Score <  0.7: {len(below_scores)} boxes\n")
            if above_scores:
                result_file.write(f" - Avg score (>= 0.7): {np.mean(above_scores):.4f}\n")
            if below_scores:
                result_file.write(f" - Avg score (< 0.7): {np.mean(below_scores):.4f}\n")
            
            if len(above_scores) > 0:
                files_with_detections += 1
            else:
                files_without_detections += 1

            result_file.write("\n" + "="*40 + "\n\n")

            # ê²°ê³¼ ì´ë¯¸ì§€ ì €ìž¥
            result_path = os.path.join(RESULT_FOLDER, filename)
            cv2.imwrite(result_path, image_cv2)
            print(f"âœ… Saved: {result_path}")
        else:
            print(f"âš ï¸ not Saved: {filename}")

    # ë£¨í”„ê°€ ëë‚œ í›„ JSON íŒŒì¼ë¡œ ì €ìž¥
    PRED_JSON_PATH = os.path.join(RESULT_FOLDER, "predictions_coco_format.json")
    with open(PRED_JSON_PATH, "w") as f:
        json.dump(coco_predictions, f, indent=4)
    print(f"ðŸ“„ COCO format prediction saved to {PRED_JSON_PATH}")

    # ì „ì²´ í†µê³„ ì¶œë ¥
    result_file.write("\nFinal Summary\n")
    result_file.write("=" * 40 + "\n")
    result_file.write(f"Total test files          : {total_files}\n")
    result_file.write(f"Files with score >= 0.7   : {files_with_detections}\n")
    result_file.write(f"Files with score <  0.7   : {files_without_detections}\n")
    if all_above_scores:
        result_file.write(f"Avg score (>= 0.7) overall: {np.mean(all_above_scores):.4f}\n")
    if all_below_scores:
        result_file.write(f"Avg score (<  0.7) overall: {np.mean(all_below_scores):.4f}\n")

print(f"ðŸ“„ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²°ê³¼ê°€ {RESULT_TXT_PATH} ì— ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
