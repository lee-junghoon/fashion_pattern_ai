import torch
import torchvision.transforms.functional as F
import torchvision.transforms as T
from torch.utils.data import Dataset, DataLoader
import json
import os
import numpy as np
from PIL import Image
from torchvision.ops import sigmoid_focal_loss

# ì €ì¥í•  JSON íŒŒì¼ ë° ì´ë¯¸ì§€ í´ë”
ANNOTATION_FILE = "annotations.json"
IMAGE_FOLDER = "dataset"
TARGET_SIZE = (300, 300)  # ëª¨ë¸ ì…ë ¥ í¬ê¸°
BATCH_SIZE = 4  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
NUM_EPOCHS = 50  # í•™ìŠµ epoch ì¦ê°€
LEARNING_RATE = 0.0003  # í•™ìŠµë¥  ê°ì†Œ
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ë°ì´í„° ë³€í™˜ ì •ì˜ (Data Augmentation ì¶”ê°€)
transform = T.Compose([
    T.Resize((300, 300)),  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),  # ìƒ‰ìƒ ë³€í˜•
    T.RandomHorizontalFlip(p=0.5),  # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „
    T.RandomRotation(degrees=15),  # 15ë„ ì´ë‚´ ëœë¤ íšŒrorcpfmf xkawl gkrl dnlgoì „
    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # ìœ„ì¹˜ ì´ë™
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ì •ê·œí™”
])

# COCO ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜
class CustomDataset(Dataset):
    def __init__(self, annotation_file, image_folder, transform=None):
        with open(annotation_file, "r") as f:
            self.data = json.load(f)
        self.image_folder = image_folder
        self.transform = transform

    def __len__(self):
        return len(self.data["images"])

    def __getitem__(self, idx):
        image_info = self.data["images"][idx]
        file_name = image_info["file_name"]
        image_path = os.path.join(self.image_folder, file_name)
        image = Image.open(image_path).convert("RGB")

        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°
        orig_width, orig_height = image.size

        # ë°”ìš´ë”© ë°•ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        valid_boxes = []
        valid_labels = []
        for ann in self.data["annotations"]:
            if ann["image_id"] == image_info["id"]:
                x, y, w, h = ann["bbox"]

                category_id = ann["category_id"]
                # # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ë³€í™˜ ë¹„ìœ¨ ê³„ì‚°
                # scale_x = TARGET_SIZE[0] / orig_width
                # scale_y = TARGET_SIZE[1] / orig_height

                # # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜
                # new_x = x * scale_x
                # new_y = y * scale_y
                # new_w = w * scale_x
                # new_h = h * scale_y

                # âœ… ë„ˆë¹„ì™€ ë†’ì´ê°€ 0ë³´ë‹¤ í° ê²½ìš°ë§Œ ì¶”ê°€
                if w > 0 and h > 0:
                    valid_boxes.append([x, y, x + w, y + h])
                    valid_labels.append(category_id)  

        # âœ… ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì—†ëŠ” ê²½ìš° í•´ë‹¹ ì´ë¯¸ì§€ í•™ìŠµì—ì„œ ì œì™¸
        if len(valid_boxes) == 0:
            return None  # ğŸš¨ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì—†ëŠ” ì´ë¯¸ì§€ëŠ” None ë°˜í™˜

        boxes = torch.as_tensor(valid_boxes, dtype=torch.float32)
        labels = torch.as_tensor(valid_labels, dtype=torch.int64)
        target = {"boxes": boxes, "labels": labels}

        # ì´ë¯¸ì§€ ë³€í™˜ ì ìš©
        if self.transform:
            #image = F.resize(image, TARGET_SIZE)  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • í›„ ë°˜í™˜
            image = F.to_tensor(image)  # í…ì„œ ë³€í™˜

        return image, target

def collate_fn(batch):
    batch = [data for data in batch if data is not None]  # ğŸš¨ None ì œê±°
    if len(batch) < 2:
        return [], []  # âœ… ë¹ˆ ë°°ì¹˜ ë°©ì§€

    images, targets = zip(*batch)  # âœ… (image, target) í˜•íƒœë¡œ Unpack
    return list(images), list(targets)

# ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ì¤€ë¹„
train_dataset = CustomDataset(ANNOTATION_FILE, IMAGE_FOLDER, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)

# SSD ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ëª¨ë¸ ë³€ê²½: ì‘ì€ ê°ì²´ íƒì§€ ê°œì„ )
import torchvision
model = torchvision.models.detection.ssdlite320_mobilenet_v3_large(pretrained=True) 
num_classes = 3  # ë°°ê²½(0) + ì²´í¬ íŒ¨í„´(1)  + ë‹¨ìƒ‰ íŒ¨í„´(2)
model.head.classification_head.num_classes = num_classes
model.to(DEVICE)

# ì˜µí‹°ë§ˆì´ì € ë° í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€
import torch.optim as optim
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)
#optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=0.0005)
#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 10 epochë§ˆë‹¤ í•™ìŠµë¥  ê°ì†Œ

# í•™ìŠµ ë£¨í”„
for epoch in range(NUM_EPOCHS):
    model.train()
    total_loss = 0

    for images, targets in train_loader:
        if len(images) == 0:
            continue

        optimizer.zero_grad()
        loss_dict = model(images, targets)
        loss = sum(loss for loss in loss_dict.values())
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    scheduler.step()
    print(f"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {total_loss:.4f}")

# í•™ìŠµëœ ëª¨ë¸ ì €ì¥
MODEL_PATH = "ssd_model_optimized.pth"
torch.save(model.state_dict(), MODEL_PATH)
print(f"Model saved to {MODEL_PATH}")
